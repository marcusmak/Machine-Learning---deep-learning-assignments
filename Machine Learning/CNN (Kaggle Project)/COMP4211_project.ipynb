{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COMP4211_project",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQzYpZTVep5K",
        "colab_type": "code",
        "outputId": "ea9b2e09-e362-47b2-e9d4-4a55b1842fd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BUtGCUP8A2I",
        "colab_type": "text"
      },
      "source": [
        "#**Load Kaggle Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8_o99hdhgJg",
        "colab_type": "code",
        "outputId": "90869e91-4402-406f-d2b3-85f7be68e377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        }
      },
      "source": [
        "!pip uninstall -y kaggle\n",
        "!pip install -upgrade pip\n",
        "!pip install kaggle==1.5.6\n",
        "!kaggle -v"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling kaggle-1.5.6:\n",
            "  Successfully uninstalled kaggle-1.5.6\n",
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n",
            "Collecting kaggle==1.5.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/bb20f9b9e24f9a6250f95a432f8d9a7d745f8d24039d7a5a6eaadb7783ba/kaggle-1.5.6.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2020.4.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle==1.5.6) (1.3)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.6-cp36-none-any.whl size=72859 sha256=e699256fe1b37a945bdb37589dba026ed532ef74cf7c571c39deaf417b40d60c\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/4e/e8/bb28d035162fb8f17f8ca5d42c3230e284c6aa565b42b72674\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.6\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/api/kaggle_api_extended.py\", line 149, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vICmAAOKEGC_",
        "colab_type": "code",
        "outputId": "dbafbf50-4cb9-4724-ef6a-c88b3b151b05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"user_name\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"key\" # key from the json file\n",
        "!kaggle competitions download -c plant-pathology-2020-fgvc7\n",
        "!unzip -q plant-pathology-2020-fgvc7.zip -d ."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading plant-pathology-2020-fgvc7.zip to /content\n",
            " 98% 766M/779M [00:09<00:00, 119MB/s] \n",
            "100% 779M/779M [00:09<00:00, 87.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH77-Oxxh_95",
        "colab_type": "code",
        "outputId": "d685b92f-03a5-4811-8917-1856e5d45071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "root_path = './'\n",
        "print(root_path + \"train.csv\")\n",
        "train_df = pd.read_csv(root_path + \"train.csv\")\n",
        "print(train_df.head())\n",
        "# test_df =  pd.read_csv(root_path + \"test.csv\")\n",
        "# sub_csv = pd.read_csv(root_path + \"sample_submission.csv\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "./train.csv\n",
            "  image_id  healthy  multiple_diseases  rust  scab\n",
            "0  Train_0        0                  0     0     1\n",
            "1  Train_1        0                  1     0     0\n",
            "2  Train_2        1                  0     0     0\n",
            "3  Train_3        0                  0     1     0\n",
            "4  Train_4        1                  0     0     0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcmiUTBbztz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class leafDataset(Dataset):\n",
        "\n",
        "    def __init__(self, root_path, dataFrame, transform = None):\n",
        "        # self.file_path = file_path\n",
        "        self.classes = list(dataFrame)[1:]\n",
        "        self.root_path = root_path\n",
        "        self.transform = transform\n",
        "        # Some preprocessing\n",
        "   \n",
        "        self.df = dataFrame\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        img_name = self.root_path + 'images/' + str(self.df.iloc[idx,0]) + '.jpg'\n",
        "        X = Image.open(img_name)\n",
        "        y = np.asarray(self.df.iloc[idx, 1:], dtype = np.float32)\n",
        "            \n",
        "        sample = {\"image\" : X , \"conditions\" : y}\n",
        "        \n",
        "        if self.transform:\n",
        "            sample['image'] = self.transform(sample['image'])\n",
        "\n",
        "        \n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sOQ_bYqGEIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize((64,96)),\n",
        "     transforms.RandomHorizontalFlip(p=0.5),\n",
        "     transforms.ToTensor(),    # range [0, 255] -> [0.0,1.0]\n",
        "     transforms.Normalize((0.5, ), (0.5, ))])  \n",
        "full_set = leafDataset(root_path,train_df,transform) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XrOmVqN8Nm6",
        "colab_type": "text"
      },
      "source": [
        "# **Split Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS6Lam6KGKCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "train_size = int(0.8 * len(full_set))\n",
        "train_set, val_set = random_split(full_set, [train_size, len(full_set)-train_size ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiS2AStX8WH4",
        "colab_type": "text"
      },
      "source": [
        "# **Model Definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxwlMrfrhKUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "model = nn.Sequential(\n",
        "          nn.Conv2d(3,16,3),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(16,16,3),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(16),\n",
        "          nn.Conv2d(16,16,3),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(2, 2),\n",
        "          nn.Conv2d(16,32,3),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(32,32,3),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(2, 2),\n",
        "          nn.Conv2d(32,64,3),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(64,64,3),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(2, 2),\n",
        "          nn.Conv2d(64,128,3),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(2, 2),\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(384,192),\n",
        "          nn.BatchNorm1d(192),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(192,48),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(48,4),\n",
        "          nn.Sigmoid()\n",
        "        )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_WRzsF_GKWC",
        "colab_type": "code",
        "outputId": "f048512d-4662-4759-dac0-0e85a1f535d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        }
      },
      "source": [
        "from torchsummary import summary\n",
        "# model = Net()\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "model.apply(init_weights)\n",
        "model = model.to(device)\n",
        "summary(model, input_size=full_set[0]['image'].shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 62, 94]             448\n",
            "              ReLU-2           [-1, 16, 62, 94]               0\n",
            "            Conv2d-3           [-1, 16, 60, 92]           2,320\n",
            "              ReLU-4           [-1, 16, 60, 92]               0\n",
            "       BatchNorm2d-5           [-1, 16, 60, 92]              32\n",
            "            Conv2d-6           [-1, 16, 58, 90]           2,320\n",
            "              ReLU-7           [-1, 16, 58, 90]               0\n",
            "         MaxPool2d-8           [-1, 16, 29, 45]               0\n",
            "            Conv2d-9           [-1, 32, 27, 43]           4,640\n",
            "             ReLU-10           [-1, 32, 27, 43]               0\n",
            "           Conv2d-11           [-1, 32, 25, 41]           9,248\n",
            "      BatchNorm2d-12           [-1, 32, 25, 41]              64\n",
            "             ReLU-13           [-1, 32, 25, 41]               0\n",
            "        MaxPool2d-14           [-1, 32, 12, 20]               0\n",
            "           Conv2d-15           [-1, 64, 10, 18]          18,496\n",
            "             ReLU-16           [-1, 64, 10, 18]               0\n",
            "           Conv2d-17            [-1, 64, 8, 16]          36,928\n",
            "      BatchNorm2d-18            [-1, 64, 8, 16]             128\n",
            "             ReLU-19            [-1, 64, 8, 16]               0\n",
            "        MaxPool2d-20             [-1, 64, 4, 8]               0\n",
            "           Conv2d-21            [-1, 128, 2, 6]          73,856\n",
            "             ReLU-22            [-1, 128, 2, 6]               0\n",
            "        MaxPool2d-23            [-1, 128, 1, 3]               0\n",
            "          Flatten-24                  [-1, 384]               0\n",
            "           Linear-25                  [-1, 192]          73,920\n",
            "      BatchNorm1d-26                  [-1, 192]             384\n",
            "             ReLU-27                  [-1, 192]               0\n",
            "           Linear-28                   [-1, 48]           9,264\n",
            "             ReLU-29                   [-1, 48]               0\n",
            "           Linear-30                    [-1, 4]             196\n",
            "          Sigmoid-31                    [-1, 4]               0\n",
            "================================================================\n",
            "Total params: 232,244\n",
            "Trainable params: 232,244\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.07\n",
            "Forward/backward pass size (MB): 6.67\n",
            "Params size (MB): 0.89\n",
            "Estimated Total Size (MB): 7.62\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSi_WFVC8cEc",
        "colab_type": "text"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3OdHB-pH0An",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_checkpoint(save_path, model, optimizer, val_loss):\n",
        "    if save_path==None:\n",
        "        return\n",
        "    save_path = save_path \n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'val_loss': val_loss}\n",
        "\n",
        "    torch.save(state_dict, save_path)\n",
        "\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_checkpoint(model, optimizer):\n",
        "    save_path = f'final_model.pt'\n",
        "    state_dict = torch.load(save_path)\n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
        "    val_loss = state_dict['val_loss']\n",
        "    print(f'Model loaded from <== {save_path}')\n",
        "    \n",
        "    return val_loss\n",
        "\n",
        "\n",
        "\n",
        "def TRAIN(net, train_loader, valid_loader,  num_epochs, eval_every, total_step, criterion, optimizer, val_loss, device, save_name):\n",
        "    train_loss_his = []\n",
        "    val_loss_his = []\n",
        "    running_loss = 0.0\n",
        "    # running_corrects = 0\n",
        "    # running_num = 0\n",
        "    global_step = 0\n",
        "    if val_loss == None:\n",
        "        best_val_loss = float(\"Inf\")  \n",
        "    else: \n",
        "        best_val_loss = val_loss\n",
        "    \n",
        "\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "        for i, samples in enumerate(train_loader):\n",
        "            inputs = samples['image']\n",
        "            labels = samples['conditions']\n",
        "            # print(inputs.shape)\n",
        "            net.train()                             # set to trainning mode\n",
        "            inputs = inputs.to(device)              \n",
        "            labels = labels.to(device)\n",
        "            '''Training of the model'''\n",
        "            # Forward pass\n",
        "            outputs = net(inputs)\n",
        "            # _, preds = torch.max(outputs.data, 1)   # get the predicted output val,index\n",
        "\n",
        "\n",
        "            loss = criterion(outputs, labels)       # calc the loss\n",
        "            \n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()                   \n",
        "            loss.backward()                         # calc grad\n",
        "            optimizer.step()                        # refreash the weight\n",
        "            global_step += 1\n",
        "\n",
        "            # print(\"here1\")\n",
        "            running_loss += loss.item()\n",
        "            # running_corrects += torch.sum(preds == labels.data)\n",
        "            # running_num += len(labels)\n",
        "            \n",
        "            '''Evaluating the model every x steps'''\n",
        "            if global_step % eval_every == 0:\n",
        "                with torch.no_grad():\n",
        "                    net.eval()\n",
        "                    val_running_loss = 0\n",
        "                    \n",
        "                    # val_running_corrects = 0\n",
        "                    for samples in valid_loader:\n",
        "                            val_inputs = samples['image'].to(device)\n",
        "                            val_labels = samples['conditions']\n",
        "                            val_outputs = net(val_inputs)\n",
        "                            val_loss = criterion(val_outputs.to(device), val_labels.to(device)).to(device)\n",
        "                            # _, preds = torch.max(val_outputs.data, 1)\n",
        "                            val_running_loss += val_loss.item()\n",
        "                            # val_running_corrects += torch.sum(preds == val_labels.data)\n",
        "\n",
        "                    average_train_loss = running_loss / eval_every\n",
        "                    average_val_loss = val_running_loss / len(valid_loader)\n",
        "                    # average_train_acc = running_corrects / float(running_num)\n",
        "                    # average_val_acc = val_running_corrects / float(len(valid_loader))\n",
        "                    train_loss_his.append(average_train_loss)\n",
        "                    val_loss_his.append(average_val_loss)\n",
        "                    print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'.format(epoch+1, num_epochs, global_step, total_step, average_train_loss,average_val_loss))\n",
        "\n",
        "                    running_loss = 0.0\n",
        "                    running_num = 0\n",
        "                    # running_corrects = 0\n",
        "                    \n",
        "                    if average_val_loss < best_val_loss:\n",
        "                        best_val_loss = average_val_loss\n",
        "                        save_checkpoint(save_name, net, optimizer, best_val_loss)\n",
        "                    \n",
        "                    \n",
        "\n",
        "    print('Finished Training')\n",
        "    return (train_loss_his,val_loss_his)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdPYG1-LGVmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 10\n",
        "eval_every = 100\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size= len(train_set)//100,\n",
        "                                          shuffle=True,num_workers=8)\n",
        "valid_loader = torch.utils.data.DataLoader(val_set, batch_size= len(val_set)//25,\n",
        "                                          shuffle=True,num_workers=8)\n",
        "\n",
        "total_step = len(train_loader)*num_epochs\n",
        "best_val_loss = None #0.1028\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters() , lr = 0.003 ,weight_decay = 1e-5)\n",
        "save_path = f'new_model.pt'\n",
        "\n",
        "\n",
        "his = TRAIN(model, train_loader, valid_loader, num_epochs, eval_every, total_step, criterion, optimizer, best_val_loss, device, save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUxurJ9S8xyx",
        "colab_type": "text"
      },
      "source": [
        "#**Print Result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deKYV92ZLTuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_his(his):\n",
        "  import matplotlib.pyplot as plt\n",
        "  y1 = his[0]\n",
        "  y2 = his[1]\n",
        "  x = range(len(his[0]))\n",
        "\n",
        "  print(best_val_loss)\n",
        "  plt.plot(x,y1,label = \"train loss\")\n",
        "  plt.plot(x,y2,label = \"val loss\")\n",
        "\n",
        "\n",
        "  plt.title(\"Loss Graph\")\n",
        "  plt.legend()  \n",
        "  plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfq2h4NJHfD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_his(his)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVrmgpmwyZhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval(net , test_loader, thersholds):\n",
        "  y_test = []\n",
        "  y_pred = {}\n",
        "  for j in thersholds:\n",
        "    y_pred[str(j)] = []\n",
        "  \n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for i in range(len(test_loader)):\n",
        "      net.eval()\n",
        "      samples = iter(test_loader).next()\n",
        "      outputs = net(samples['image'].to(device))\n",
        "      labels = samples['conditions']\n",
        "      labels = labels.cpu()\n",
        "      for thershold in thersholds:\n",
        "        predicted = torch.where(outputs > thershold, torch.Tensor([1]).to(device) , torch.Tensor([0]).to(device))\n",
        "        predicted = predicted.cpu()\n",
        "        y_pred[str(thershold)].append(predicted)\n",
        "      y_test.append(labels)\n",
        "  return y_test, y_pred\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfzE8Rrt2WLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_loader = torch.utils.data.DataLoader(val_set, batch_size= len(val_set)//25,\n",
        "                                          shuffle=True,num_workers=8)\n",
        "thersholds = [0.5] # np.arange(0.1,1,0.1)\n",
        "y_test, y_pred = eval(model,valid_loader, thersholds)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-ew9ha95DPj",
        "colab_type": "code",
        "outputId": "dd9241d7-0042-4fdd-84bf-136296d75392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "try:\n",
        "  y_test = torch.stack(y_test)\n",
        "except:\n",
        "  pass\n",
        "for i in thersholds:\n",
        "  try:\n",
        "    y_pred[str(i)] = torch.stack(y_pred[str(i)])\n",
        "  except:\n",
        "    pass\n",
        "  class_re = classification_report(y_test.reshape(-1,4) , y_pred[str(i)].reshape(-1,4), zero_division=0)\n",
        "  acc = accuracy_score(y_test.reshape(-1,4) , y_pred[str(i)].reshape(-1,4))\n",
        "  print(f'Thershold {round(i*10)/10} (with accuacry {acc}) report:\\n {class_re}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thershold 0.5 (with accuacry 0.9365079365079365) report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.95      0.96       122\n",
            "           1       0.50      0.08      0.13        13\n",
            "           2       0.96      0.98      0.97       112\n",
            "           3       0.93      0.98      0.96       131\n",
            "\n",
            "   micro avg       0.95      0.94      0.94       378\n",
            "   macro avg       0.84      0.75      0.75       378\n",
            "weighted avg       0.94      0.94      0.93       378\n",
            " samples avg       0.94      0.94      0.94       378\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoqKnWNr8meJ",
        "colab_type": "text"
      },
      "source": [
        "# **Load Pre-trained Best Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7lDBQlpAF2g",
        "colab_type": "code",
        "outputId": "82750a5a-14b7-486d-a2fd-12cf8a579f92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "def load_checkpoint(model, optimizer):\n",
        "    save_path = f'final_model.pt'\n",
        "    state_dict = torch.load(save_path)\n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
        "    val_loss = state_dict['val_loss']\n",
        "    print(f'Model loaded from <== {save_path}')\n",
        "    \n",
        "    return val_loss\n",
        "optimizer = optim.Adam(model.parameters() , lr = 0.001 ,weight_decay = 1e-5)\n",
        "best_val_loss = load_checkpoint(model, optimizer)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded from <== final_model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f21we3N2V9bi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ed24399b-d80c-44c0-c2a4-e612bc1b73c9"
      },
      "source": [
        "print(best_val_loss)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.10283864729313387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-7Df-9W9lPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}